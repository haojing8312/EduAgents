"""
Redisç¼“å­˜å·¥å…·æ¨¡å— - å¢å¼ºç‰ˆ
æä¾›å¼‚æ­¥Redisè¿æ¥å’Œæ™ºèƒ½ç¼“å­˜ç­–ç•¥ï¼Œä¼˜åŒ–AIæ™ºèƒ½ä½“åä½œæ€§èƒ½
"""

import json
import logging
import hashlib
from typing import Any, Dict, List, Optional, Union
from datetime import datetime, timedelta
import pickle
import redis.asyncio as aioredis
from contextlib import asynccontextmanager

from .config import settings


logger = logging.getLogger(__name__)


class CacheKeyManager:
    """ç¼“å­˜é”®ç®¡ç†å™¨ - ç»Ÿä¸€ç®¡ç†ç¼“å­˜é”®çš„å‘½åè§„åˆ™"""

    # ç¼“å­˜é”®å‰ç¼€
    PREFIX_AGENT_RESULT = "agent:result"
    PREFIX_COURSE_DESIGN = "course:design"
    PREFIX_SESSION_STATE = "session:state"
    PREFIX_LLM_RESPONSE = "llm:response"
    PREFIX_USER_CONTEXT = "user:context"
    PREFIX_TEMPLATE = "template"
    PREFIX_EXPORT = "export"

    @staticmethod
    def agent_result_key(agent_id: str, requirement_hash: str) -> str:
        """æ™ºèƒ½ä½“ç»“æœç¼“å­˜é”®"""
        return f"{CacheKeyManager.PREFIX_AGENT_RESULT}:{agent_id}:{requirement_hash}"

    @staticmethod
    def course_design_key(session_id: str) -> str:
        """è¯¾ç¨‹è®¾è®¡ç¼“å­˜é”®"""
        return f"{CacheKeyManager.PREFIX_COURSE_DESIGN}:{session_id}"

    @staticmethod
    def session_state_key(session_id: str) -> str:
        """ä¼šè¯çŠ¶æ€ç¼“å­˜é”®"""
        return f"{CacheKeyManager.PREFIX_SESSION_STATE}:{session_id}"

    @staticmethod
    def llm_response_key(prompt_hash: str, model: str) -> str:
        """LLMå“åº”ç¼“å­˜é”®"""
        return f"{CacheKeyManager.PREFIX_LLM_RESPONSE}:{model}:{prompt_hash}"

    @staticmethod
    def user_context_key(user_id: str) -> str:
        """ç”¨æˆ·ä¸Šä¸‹æ–‡ç¼“å­˜é”®"""
        return f"{CacheKeyManager.PREFIX_USER_CONTEXT}:{user_id}"

    @staticmethod
    def template_key(template_type: str, template_id: str) -> str:
        """æ¨¡æ¿ç¼“å­˜é”®"""
        return f"{CacheKeyManager.PREFIX_TEMPLATE}:{template_type}:{template_id}"

    @staticmethod
    def export_key(course_id: str, format_type: str) -> str:
        """å¯¼å‡ºæ–‡ä»¶ç¼“å­˜é”®"""
        return f"{CacheKeyManager.PREFIX_EXPORT}:{course_id}:{format_type}"

    @staticmethod
    def hash_content(content: Union[str, Dict, List]) -> str:
        """ç”Ÿæˆå†…å®¹çš„å“ˆå¸Œå€¼"""
        if isinstance(content, (dict, list)):
            content = json.dumps(content, sort_keys=True, ensure_ascii=False)
        return hashlib.md5(content.encode('utf-8')).hexdigest()


class SmartCacheManager:
    """æ™ºèƒ½ç¼“å­˜ç®¡ç†å™¨ - é’ˆå¯¹AIåä½œåœºæ™¯ä¼˜åŒ–"""

    def __init__(self):
        self.general_redis: Optional[aioredis.Redis] = None
        self.cache_redis: Optional[aioredis.Redis] = None
        self.session_redis: Optional[aioredis.Redis] = None
        self.initialized = False

    async def init_redis_connections(self):
        """åˆå§‹åŒ–å¤šä¸ªRedisè¿æ¥"""
        try:
            # é€šç”¨Redisè¿æ¥ (DB 0)
            self.general_redis = aioredis.from_url(
                settings.REDIS_URL,
                encoding="utf-8",
                decode_responses=True,
                max_connections=20
            )

            # ç¼“å­˜ä¸“ç”¨Redisè¿æ¥ (DB 1)
            self.cache_redis = aioredis.from_url(
                settings.REDIS_CACHE_URL,
                encoding="utf-8",
                decode_responses=True,
                max_connections=30
            )

            # ä¼šè¯ä¸“ç”¨Redisè¿æ¥ (DB 2)
            self.session_redis = aioredis.from_url(
                settings.REDIS_SESSION_URL,
                encoding="utf-8",
                decode_responses=True,
                max_connections=20
            )

            # æµ‹è¯•æ‰€æœ‰è¿æ¥
            await self.general_redis.ping()
            await self.cache_redis.ping()
            await self.session_redis.ping()

            self.initialized = True
            logger.info("âœ… Rediså¤šæ•°æ®åº“è¿æ¥åˆå§‹åŒ–æˆåŠŸ")

        except Exception as e:
            logger.warning(f"âš ï¸ Redisè¿æ¥å¤±è´¥: {e}")
            self.initialized = False

    def _get_redis_by_type(self, cache_type: str) -> Optional[aioredis.Redis]:
        """æ ¹æ®ç¼“å­˜ç±»å‹è·å–å¯¹åº”çš„Redisè¿æ¥"""
        if not self.initialized:
            return None

        if cache_type in ["session", "websocket"]:
            return self.session_redis
        elif cache_type in ["cache", "agent", "llm", "template", "export"]:
            return self.cache_redis
        else:
            return self.general_redis

    async def get(self, key: str, cache_type: str = "cache") -> Optional[Any]:
        """è·å–ç¼“å­˜å€¼"""
        redis_conn = self._get_redis_by_type(cache_type)
        if not redis_conn:
            return None

        try:
            value = await redis_conn.get(key)
            if value is None:
                return None

            # å°è¯•è§£æJSONï¼Œå¤±è´¥åˆ™è¿”å›åŸå§‹å­—ç¬¦ä¸²
            try:
                return json.loads(value)
            except (json.JSONDecodeError, TypeError):
                return value

        except Exception as e:
            logger.error(f"ç¼“å­˜è·å–å¤±è´¥ [{key}]: {e}")
            return None

    async def set(
        self,
        key: str,
        value: Any,
        expire: int = None,
        cache_type: str = "cache"
    ) -> bool:
        """è®¾ç½®ç¼“å­˜å€¼"""
        redis_conn = self._get_redis_by_type(cache_type)
        if not redis_conn:
            return False

        try:
            # è‡ªåŠ¨é€‰æ‹©åºåˆ—åŒ–æ–¹å¼
            if isinstance(value, (dict, list)):
                serialized_value = json.dumps(value, ensure_ascii=False, default=str)
            else:
                serialized_value = str(value)

            # ä½¿ç”¨é…ç½®çš„é»˜è®¤è¿‡æœŸæ—¶é—´
            if expire is None:
                expire = self._get_default_ttl(cache_type)

            await redis_conn.set(key, serialized_value, ex=expire)
            logger.debug(f"ç¼“å­˜è®¾ç½®æˆåŠŸ [{key}] TTL: {expire}s")
            return True

        except Exception as e:
            logger.error(f"ç¼“å­˜è®¾ç½®å¤±è´¥ [{key}]: {e}")
            return False

    def _get_default_ttl(self, cache_type: str) -> int:
        """æ ¹æ®ç¼“å­˜ç±»å‹è·å–é»˜è®¤TTL"""
        ttl_mapping = {
            "session": settings.CACHE_TTL_SHORT,      # 5åˆ†é’Ÿ
            "agent": settings.CACHE_TTL_MEDIUM,       # 30åˆ†é’Ÿ
            "llm": settings.CACHE_TTL_LONG,           # 1å°æ—¶
            "template": settings.CACHE_TTL_LONG * 24, # 24å°æ—¶
            "export": settings.CACHE_TTL_MEDIUM,      # 30åˆ†é’Ÿ
            "cache": settings.CACHE_TTL_MEDIUM        # é»˜è®¤30åˆ†é’Ÿ
        }
        return ttl_mapping.get(cache_type, settings.CACHE_TTL_MEDIUM)

    async def delete(self, key: str, cache_type: str = "cache") -> bool:
        """åˆ é™¤ç¼“å­˜"""
        redis_conn = self._get_redis_by_type(cache_type)
        if not redis_conn:
            return False

        try:
            await redis_conn.delete(key)
            logger.debug(f"ç¼“å­˜åˆ é™¤æˆåŠŸ [{key}]")
            return True
        except Exception as e:
            logger.error(f"ç¼“å­˜åˆ é™¤å¤±è´¥ [{key}]: {e}")
            return False

    async def delete_pattern(self, pattern: str, cache_type: str = "cache") -> int:
        """æ‰¹é‡åˆ é™¤åŒ¹é…æ¨¡å¼çš„ç¼“å­˜é”®"""
        redis_conn = self._get_redis_by_type(cache_type)
        if not redis_conn:
            return 0

        try:
            keys = await redis_conn.keys(pattern)
            if keys:
                deleted_count = await redis_conn.delete(*keys)
                logger.info(f"æ‰¹é‡åˆ é™¤ç¼“å­˜ [{pattern}]: {deleted_count}ä¸ªé”®")
                return deleted_count
            return 0
        except Exception as e:
            logger.error(f"æ‰¹é‡åˆ é™¤ç¼“å­˜å¤±è´¥ [{pattern}]: {e}")
            return 0

    async def exists(self, key: str, cache_type: str = "cache") -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦å­˜åœ¨"""
        redis_conn = self._get_redis_by_type(cache_type)
        if not redis_conn:
            return False

        try:
            return bool(await redis_conn.exists(key))
        except Exception as e:
            logger.error(f"ç¼“å­˜å­˜åœ¨æ€§æ£€æŸ¥å¤±è´¥ [{key}]: {e}")
            return False

    async def get_ttl(self, key: str, cache_type: str = "cache") -> Optional[int]:
        """è·å–ç¼“å­˜å‰©ä½™è¿‡æœŸæ—¶é—´"""
        redis_conn = self._get_redis_by_type(cache_type)
        if not redis_conn:
            return None

        try:
            ttl = await redis_conn.ttl(key)
            return ttl if ttl > 0 else None
        except Exception as e:
            logger.error(f"è·å–TTLå¤±è´¥ [{key}]: {e}")
            return None

    async def extend_ttl(self, key: str, seconds: int, cache_type: str = "cache") -> bool:
        """å»¶é•¿ç¼“å­˜è¿‡æœŸæ—¶é—´"""
        redis_conn = self._get_redis_by_type(cache_type)
        if not redis_conn:
            return False

        try:
            return bool(await redis_conn.expire(key, seconds))
        except Exception as e:
            logger.error(f"å»¶é•¿TTLå¤±è´¥ [{key}]: {e}")
            return False

    @asynccontextmanager
    async def pipeline(self, cache_type: str = "cache"):
        """Redisç®¡é“ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        redis_conn = self._get_redis_by_type(cache_type)
        if not redis_conn:
            yield None
            return

        pipe = redis_conn.pipeline()
        try:
            yield pipe
            await pipe.execute()
        except Exception as e:
            logger.error(f"ç®¡é“æ‰§è¡Œå¤±è´¥: {e}")
            await pipe.reset()

    async def get_cache_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            "initialized": self.initialized,
            "connections": {},
            "memory_usage": {},
            "key_counts": {}
        }

        if not self.initialized:
            return stats

        try:
            # æ£€æŸ¥å„è¿æ¥çŠ¶æ€
            for name, redis_conn in [
                ("general", self.general_redis),
                ("cache", self.cache_redis),
                ("session", self.session_redis)
            ]:
                if redis_conn:
                    try:
                        await redis_conn.ping()
                        info = await redis_conn.info("memory")
                        stats["connections"][name] = "connected"
                        stats["memory_usage"][name] = info.get("used_memory_human", "unknown")

                        # è·å–é”®æ•°é‡
                        db_size = await redis_conn.dbsize()
                        stats["key_counts"][name] = db_size

                    except Exception as e:
                        stats["connections"][name] = f"error: {e}"

        except Exception as e:
            logger.error(f"è·å–ç¼“å­˜ç»Ÿè®¡å¤±è´¥: {e}")

        return stats

    async def close_all_connections(self):
        """å…³é—­æ‰€æœ‰Redisè¿æ¥"""
        for redis_conn in [self.general_redis, self.cache_redis, self.session_redis]:
            if redis_conn:
                try:
                    await redis_conn.close()
                except Exception as e:
                    logger.error(f"å…³é—­Redisè¿æ¥å¤±è´¥: {e}")

        self.initialized = False
        logger.info("æ‰€æœ‰Redisè¿æ¥å·²å…³é—­")


class AgentResultCache:
    """æ™ºèƒ½ä½“ç»“æœä¸“ç”¨ç¼“å­˜ç±»"""

    def __init__(self, cache_manager: SmartCacheManager):
        self.cache_manager = cache_manager

    async def get_agent_result(self, agent_id: str, course_requirement: str) -> Optional[Dict[str, Any]]:
        """è·å–æ™ºèƒ½ä½“æ‰§è¡Œç»“æœ"""
        requirement_hash = CacheKeyManager.hash_content(course_requirement)
        key = CacheKeyManager.agent_result_key(agent_id, requirement_hash)

        result = await self.cache_manager.get(key, cache_type="agent")
        if result:
            logger.info(f"ğŸ¯ æ™ºèƒ½ä½“ç»“æœç¼“å­˜å‘½ä¸­: {agent_id}")
        return result

    async def cache_agent_result(
        self,
        agent_id: str,
        course_requirement: str,
        result: Dict[str, Any]
    ) -> bool:
        """ç¼“å­˜æ™ºèƒ½ä½“æ‰§è¡Œç»“æœ"""
        requirement_hash = CacheKeyManager.hash_content(course_requirement)
        key = CacheKeyManager.agent_result_key(agent_id, requirement_hash)

        # ä¸ºç»“æœæ·»åŠ ç¼“å­˜å…ƒæ•°æ®
        cached_result = {
            "agent_id": agent_id,
            "requirement_hash": requirement_hash,
            "result": result,
            "cached_at": datetime.now().isoformat(),
            "cache_version": "1.0"
        }

        success = await self.cache_manager.set(
            key,
            cached_result,
            cache_type="agent"
        )

        if success:
            logger.info(f"ğŸ’¾ æ™ºèƒ½ä½“ç»“æœå·²ç¼“å­˜: {agent_id}")

        return success

    async def invalidate_agent_cache(self, agent_id: str) -> int:
        """æ¸…é™¤ç‰¹å®šæ™ºèƒ½ä½“çš„æ‰€æœ‰ç¼“å­˜"""
        pattern = f"{CacheKeyManager.PREFIX_AGENT_RESULT}:{agent_id}:*"
        return await self.cache_manager.delete_pattern(pattern, cache_type="agent")


class SessionStateCache:
    """ä¼šè¯çŠ¶æ€ä¸“ç”¨ç¼“å­˜ç±»"""

    def __init__(self, cache_manager: SmartCacheManager):
        self.cache_manager = cache_manager

    async def get_session_state(self, session_id: str) -> Optional[Dict[str, Any]]:
        """è·å–ä¼šè¯çŠ¶æ€"""
        key = CacheKeyManager.session_state_key(session_id)
        return await self.cache_manager.get(key, cache_type="session")

    async def update_session_state(self, session_id: str, state: Dict[str, Any]) -> bool:
        """æ›´æ–°ä¼šè¯çŠ¶æ€"""
        key = CacheKeyManager.session_state_key(session_id)

        # ä¸ºçŠ¶æ€æ·»åŠ æ—¶é—´æˆ³
        state_with_timestamp = {
            **state,
            "updated_at": datetime.now().isoformat(),
            "session_id": session_id
        }

        return await self.cache_manager.set(
            key,
            state_with_timestamp,
            cache_type="session"
        )

    async def extend_session(self, session_id: str, seconds: int = None) -> bool:
        """å»¶é•¿ä¼šè¯æœ‰æ•ˆæœŸ"""
        key = CacheKeyManager.session_state_key(session_id)
        if seconds is None:
            seconds = settings.CACHE_TTL_SHORT * 2  # é»˜è®¤å»¶é•¿10åˆ†é’Ÿ

        return await self.cache_manager.extend_ttl(key, seconds, cache_type="session")

    async def end_session(self, session_id: str) -> bool:
        """ç»“æŸä¼šè¯"""
        key = CacheKeyManager.session_state_key(session_id)
        return await self.cache_manager.delete(key, cache_type="session")


class LLMResponseCache:
    """LLMå“åº”ä¸“ç”¨ç¼“å­˜ç±»"""

    def __init__(self, cache_manager: SmartCacheManager):
        self.cache_manager = cache_manager

    async def get_llm_response(self, prompt: str, model: str) -> Optional[str]:
        """è·å–LLMå“åº”ç¼“å­˜"""
        prompt_hash = CacheKeyManager.hash_content(prompt)
        key = CacheKeyManager.llm_response_key(prompt_hash, model)

        cached_response = await self.cache_manager.get(key, cache_type="llm")
        if cached_response:
            logger.info(f"ğŸ¤– LLMå“åº”ç¼“å­˜å‘½ä¸­: {model}")
            return cached_response.get("response") if isinstance(cached_response, dict) else cached_response

        return None

    async def cache_llm_response(self, prompt: str, model: str, response: str) -> bool:
        """ç¼“å­˜LLMå“åº”"""
        prompt_hash = CacheKeyManager.hash_content(prompt)
        key = CacheKeyManager.llm_response_key(prompt_hash, model)

        cached_data = {
            "prompt_hash": prompt_hash,
            "model": model,
            "response": response,
            "cached_at": datetime.now().isoformat(),
            "token_count": len(response.split()) if response else 0
        }

        success = await self.cache_manager.set(
            key,
            cached_data,
            cache_type="llm"
        )

        if success:
            logger.info(f"ğŸ’¾ LLMå“åº”å·²ç¼“å­˜: {model}")

        return success


# å…¨å±€ç¼“å­˜ç®¡ç†å™¨å®ä¾‹
smart_cache_manager = SmartCacheManager()

# ä¸“ç”¨ç¼“å­˜å®ä¾‹
agent_cache: Optional[AgentResultCache] = None
session_cache: Optional[SessionStateCache] = None
llm_cache: Optional[LLMResponseCache] = None


async def init_enhanced_redis():
    """åˆå§‹åŒ–å¢å¼ºç‰ˆRedisç¼“å­˜ç³»ç»Ÿ"""
    global agent_cache, session_cache, llm_cache

    await smart_cache_manager.init_redis_connections()

    if smart_cache_manager.initialized:
        agent_cache = AgentResultCache(smart_cache_manager)
        session_cache = SessionStateCache(smart_cache_manager)
        llm_cache = LLMResponseCache(smart_cache_manager)
        logger.info("ğŸš€ å¢å¼ºç‰ˆRedisç¼“å­˜ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    else:
        logger.warning("âš ï¸ Redisç¼“å­˜ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨å†…å­˜ç¼“å­˜")


async def close_enhanced_redis():
    """å…³é—­å¢å¼ºç‰ˆRedisç¼“å­˜ç³»ç»Ÿ"""
    await smart_cache_manager.close_all_connections()


# å…¼å®¹æ€§å‡½æ•° - ä¿æŒå‘åå…¼å®¹
async def get_cache(key: str) -> Optional[Any]:
    """è·å–ç¼“å­˜ï¼ˆå…¼å®¹æ€§å‡½æ•°ï¼‰"""
    return await smart_cache_manager.get(key)


async def set_cache(key: str, value: Any, expire: int = None) -> bool:
    """è®¾ç½®ç¼“å­˜ï¼ˆå…¼å®¹æ€§å‡½æ•°ï¼‰"""
    return await smart_cache_manager.set(key, value, expire)


async def delete_cache(key: str) -> bool:
    """åˆ é™¤ç¼“å­˜ï¼ˆå…¼å®¹æ€§å‡½æ•°ï¼‰"""
    return await smart_cache_manager.delete(key)


# ç»Ÿè®¡å’Œç›‘æ§å‡½æ•°
async def get_cache_health() -> Dict[str, Any]:
    """è·å–ç¼“å­˜ç³»ç»Ÿå¥åº·çŠ¶æ€"""
    stats = await smart_cache_manager.get_cache_stats()

    return {
        "status": "healthy" if stats["initialized"] else "unhealthy",
        "timestamp": datetime.now().isoformat(),
        "details": stats
    }